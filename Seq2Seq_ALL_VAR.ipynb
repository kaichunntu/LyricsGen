{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as ly\n",
    "sess_opt = tf.ConfigProto(gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.95 , allow_growth=True)\n",
    "                         ,device_count={'GPU': 1})\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils import exist_or_mkdir , data_manager , transform_word , transform_gramma , transform_rhy\n",
    "\n",
    "exp_folder = \"ALL_ver0\"\n",
    "model_path = \"model_para\"\n",
    "tmp_path = \"tmp\"\n",
    "log_path = \"log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path : './ALL_ver0'\n",
      "Path : './ALL_ver0/model_para'\n",
      "Path : './ALL_ver0/tmp'\n",
      "Path : './ALL_ver0/log'\n"
     ]
    }
   ],
   "source": [
    "exp_folder = exist_or_mkdir(\"./\",exp_folder)\n",
    "model_path = exist_or_mkdir(exp_folder,model_path)\n",
    "tmp_path = exist_or_mkdir(exp_folder,tmp_path)\n",
    "log_path = exist_or_mkdir(exp_folder,log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 20\n",
    "min_count = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Loading Train Data ###\n",
      "Data count : 651339\n",
      "\n",
      "### Data view ###\n",
      "Input sentence : ['SOS', '记得', '在', '我', '回来', '之前', '可别', '把', '她们', '给', '放跑', 'EOS']\n",
      "Gramma         : ['n', 'f', 'v', 'uz', 'a', 'v', 'uj', 'z', 'nr']\n",
      "Length         : 9\n",
      "Rhyme          : ing\n",
      "Output Sentence : ['SOS', '帐篷', '里面', '挂', '着', '最', '喜欢', '的', '摇滚', '明星', 'EOS']\n"
     ]
    }
   ],
   "source": [
    "print(\"### Loading Train Data ###\")\n",
    "data_agent = data_manager(\"data/all/train.csv\" , train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Loading Test Data ###\n",
      "Data count : 70000\n",
      "\n",
      "### Data view ###\n",
      "Input sentence : ['SOS', '你', '看着', '睡着', '了', '的', '我', 'EOS']\n",
      "Gramma         : ['d', 'v', 'uz', 'e', 'r', 'd', 'v', 'a']\n",
      "Length         : 8\n",
      "Rhyme          : u\n"
     ]
    }
   ],
   "source": [
    "print(\"### Loading Test Data ###\")\n",
    "test_agent = data_manager(\"data/all/test.csv\" , train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Count : 3\n",
      "Max Length : 20\n",
      "Word Count : 59348\n"
     ]
    }
   ],
   "source": [
    "idx_in_sen , idx_out_sen , mask_in , mask_out , idx2word , word2idx , remain_idx = \\\n",
    "    transform_word([data_agent.in_sen , data_agent.out_sen],min_count=min_count,max_len = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gramma Count : 57\n"
     ]
    }
   ],
   "source": [
    "idx_gramma , idx2gramma , gramma2idx = transform_gramma(data_agent.gramma , remain_idx,max_len = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length :  18\n"
     ]
    }
   ],
   "source": [
    "length = np.array(data_agent.length)[remain_idx]\n",
    "print(\"Max length : \" , max(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rhyme Count : 35\n"
     ]
    }
   ],
   "source": [
    "idx_rhy , rhy2idx , idx2rhy = transform_rhy(data_agent.rhyme,remain_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((650447,), (650447,), (650447, 20), (650447, 20), (650447, 20))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_rhy.shape , length.shape , idx_in_sen.shape , idx_out_sen.shape , idx_gramma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump({\"word\":[idx2word,word2idx] , \"rhyme\":[idx2rhy,rhy2idx] , \"gramma\":[idx2gramma,gramma2idx]},\n",
    "            open(os.path.join(tmp_path,\"tokenizer.pkl\") , \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder(inputs , dim , name , init_state=None , t_len=20 , reuse=False , stack_flag=False):\n",
    "    cell = tf.contrib.rnn.LSTMCell(dim,name=name,reuse=reuse)\n",
    "    if init_state:\n",
    "        state = init_state\n",
    "    else:\n",
    "        state = [tf.zeros([tf.shape(inputs)[0] , cell.state_size[0]]),\n",
    "                 tf.zeros([tf.shape(inputs)[0] , cell.state_size[1]])]\n",
    "    output_seq = []\n",
    "    for t in range(t_len):\n",
    "        if stack_flag:\n",
    "            out , state = cell(inputs[:,t] , state)\n",
    "        else:\n",
    "            out , state = cell(inputs[t] , state)\n",
    "        output_seq.append(out)\n",
    "    \n",
    "    return output_seq , state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attend_vector(inputs , state , mask , name):\n",
    "    with tf.name_scope(\"Attention\"):\n",
    "        state = tf.tile(tf.expand_dims(state , axis=1) , [1,tf.shape(inputs)[1],1])\n",
    "        concat_vec = tf.concat([inputs,state],axis=-1)\n",
    "        fc1 = ly.fully_connected(concat_vec,128,activation_fn=tf.nn.leaky_relu,biases_initializer=None,\n",
    "                                 scope=\"Attn_{}_1\".format(name),reuse=tf.AUTO_REUSE)\n",
    "        fc2 = ly.fully_connected(fc1,64,activation_fn=tf.nn.leaky_relu,biases_initializer=None,\n",
    "                                 scope=\"Attn_{}_2\".format(name),reuse=tf.AUTO_REUSE)\n",
    "        fc3 = ly.fully_connected(fc1,1,activation_fn=None,biases_initializer=None,\n",
    "                                 scope=\"Attn_{}_3\".format(name),reuse=tf.AUTO_REUSE)\n",
    "        score = tf.nn.softmax(fc3*mask , axis=1)\n",
    "    \n",
    "    return score , tf.reduce_sum(inputs*score , axis=1)\n",
    "\n",
    "def attn_Encoder(inputs , mask , dim , name , init_state=None , t_len=20 , reuse=False):\n",
    "    cell = tf.contrib.rnn.LSTMCell(dim,name=name,reuse=reuse)\n",
    "    if init_state:\n",
    "        state = init_state\n",
    "    else:\n",
    "        state = [tf.zeros([tf.shape(inputs)[0] , cell.state_size[0]]),\n",
    "                 tf.zeros([tf.shape(inputs)[0] , cell.state_size[1]])]\n",
    "    output_seq = []\n",
    "    score_seq = []\n",
    "    for t in range(t_len):\n",
    "        score , attn_vec = attend_vector(inputs,state[1],mask,name=\"Encode\")\n",
    "        out , state = cell(attn_vec,state)\n",
    "        output_seq.append(out)\n",
    "        score_seq.append(score)\n",
    "    \n",
    "    return output_seq , state , score_seq \n",
    "\n",
    "\n",
    "def attn_Decoder(inputs , inputs_E , mask , dim , name , init_state=None , t_len=20 , reuse=False , stack_flag=False):\n",
    "    cell = tf.contrib.rnn.LSTMCell(dim,name=name,reuse=reuse)\n",
    "    if init_state:\n",
    "        state = init_state\n",
    "    else:\n",
    "        state = [tf.zeros([tf.shape(inputs)[0] , cell.state_size[0]]),\n",
    "                 tf.zeros([tf.shape(inputs)[0] , cell.state_size[1]])]\n",
    "    output_seq = []\n",
    "    score_seq = []\n",
    "    for t in range(t_len):\n",
    "        score , attn_vec = attend_vector(inputs_E,state[1],mask,name=\"Decode\")\n",
    "        if stack_flag:\n",
    "            attn_vec = tf.concat([attn_vec,inputs[:,t]] , axis=-1)\n",
    "        else:\n",
    "            attn_vec = tf.concat([attn_vec,inputs[t]] , axis=-1)\n",
    "        out , state = cell(attn_vec,state)\n",
    "        output_seq.append(out)\n",
    "        score_seq.append(score)\n",
    "    \n",
    "    return output_seq , state , score_seq \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_clf(inputs,embd):\n",
    "    fc1 = ly.fully_connected(inputs,128,activation_fn=tf.nn.leaky_relu,scope=\"clf_fc1\",reuse=tf.AUTO_REUSE)\n",
    "    fc2 = ly.fully_connected(fc1,128,activation_fn=None,scope=\"clf_fc2\",reuse=tf.AUTO_REUSE)\n",
    "    return fc2@embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_catece(x):\n",
    "    logit = x[0]\n",
    "    idx = x[1]\n",
    "    ce = []\n",
    "    for t in range(max_len-1):\n",
    "        ce.append( tf.log(tf.nn.embedding_lookup(logit[t],idx[t])+1e-10) )\n",
    "    return tf.stack(ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7e669fe13bfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSeq_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0membd_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membd_gra_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0membd_rhy_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0membd_len_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "Seq_g = tf.Graph()\n",
    "embd_dim = 128\n",
    "embd_gra_dim = 32\n",
    "embd_rhy_dim = 16\n",
    "embd_len_dim = 16\n",
    "\n",
    "with Seq_g.as_default():\n",
    "    with tf.name_scope(\"Input\"):\n",
    "        _in = tf.placeholder(tf.int32,[None,max_len])\n",
    "        _in_mask = tf.placeholder(tf.float32,[None,max_len])\n",
    "        in_mask = tf.expand_dims(_in_mask,axis=-1)\n",
    "        \n",
    "        _out = tf.placeholder(tf.int32,[None,max_len])\n",
    "        _out_mask = tf.placeholder(tf.float32,[None,max_len])\n",
    "        \n",
    "        gt = _out[:,1::]\n",
    "        gt_mask = _out_mask[:,1::]\n",
    "        \n",
    "        _out_gra = tf.placeholder(tf.int32,[None,max_len])\n",
    "        _out_len = tf.placeholder(tf.float32,[None])\n",
    "        _out_rhy = tf.placeholder(tf.int32,[None])\n",
    "        \n",
    "        infer_start = tf.placeholder(tf.int32,[None])\n",
    "        \n",
    "    with tf.name_scope(\"Embedding\"):\n",
    "        ## word embedding\n",
    "        _embd = tf.Variable(tf.truncated_normal([len(idx2word) , embd_dim],stddev=0.1),name=\"Word_Embd\")\n",
    "        _embd_T = tf.transpose(_embd,[1,0])\n",
    "        x_vector = tf.nn.embedding_lookup(_embd,_in,max_norm=5)\n",
    "        y_vector = tf.nn.embedding_lookup(_embd,_out,max_norm=5)\n",
    "        \n",
    "        ## gramma embedding\n",
    "        _embd_gra = tf.Variable(tf.truncated_normal([len(idx2gramma) , embd_gra_dim],stddev=0.1),name=\"Gramma_Embd\")\n",
    "        gra_vector = tf.nn.embedding_lookup(_embd_gra,_out_gra,max_norm=1)\n",
    "        \n",
    "        ## rhyme embedding\n",
    "        _embd_rhy = tf.Variable(tf.truncated_normal([len(idx2rhy) , embd_rhy_dim],stddev=0.1),name=\"Rhyme_Embd\")\n",
    "        rhy_vector = tf.nn.embedding_lookup(_embd_rhy,_out_rhy,max_norm=1)\n",
    "        \n",
    "        ## length embedding\n",
    "        _embd_len = tf.Variable(tf.truncated_normal([1 , embd_len_dim],stddev=0.1),name=\"Rhyme_Embd\")\n",
    "        \n",
    "        len_vector = tf.matmul(tf.expand_dims(_out_len,axis=1),_embd_len)\n",
    "        time_vector = [len_vector]\n",
    "        for _ in range(max_len-1):\n",
    "            len_vector = ly.fully_connected(len_vector,embd_len_dim,activation_fn=None,\n",
    "                                            scope=\"Time_transform\",reuse=tf.AUTO_REUSE)\n",
    "            time_vector.append(len_vector)\n",
    "        time_vector = tf.stack(time_vector,axis=1)\n",
    "        \n",
    "        var_vector = tf.concat([gra_vector,time_vector,\n",
    "                                tf.tile(tf.expand_dims(rhy_vector,axis=1),[1,max_len,1])] ,axis=-1)\n",
    "        var_vector = ly.fully_connected(var_vector,64,activation_fn=tf.nn.leaky_relu,biases_initializer=None,\n",
    "                                        scope=\"Var_transform\" , reuse=tf.AUTO_REUSE)\n",
    "        \n",
    "        \n",
    "    with tf.name_scope(\"Encoder\"):\n",
    "        E_layer1 , e_state_1 = Encoder(x_vector,256,t_len=max_len,name=\"E_layer_1\",stack_flag=True)\n",
    "        E_layer2 , e_state_2 , E_score_seq = attn_Encoder(tf.stack(E_layer1,axis=1),in_mask,256,\n",
    "                                                          t_len=max_len,name=\"ATTN_E_layer2\")\n",
    "        \n",
    "        \n",
    "    with tf.name_scope(\"Decoder\"):\n",
    "        concat_out_vector = tf.concat([y_vector,var_vector],axis=-1)\n",
    "        D_layer0 , d_state_0 = Encoder(concat_out_vector,128,name=\"D_layer0\",t_len=max_len,stack_flag=True)\n",
    "        D_layer1 , d_state_1 = Encoder(D_layer0,256,init_state=e_state_1,\n",
    "                                       t_len=max_len,name=\"E_layer_1\",reuse=True,stack_flag=False)\n",
    "        D_layer2 , d_state_2 , D_score_seq = attn_Decoder(D_layer1,tf.stack(E_layer2,axis=1),in_mask,256,init_state=e_state_2,\n",
    "                                                          name=\"ATTN_D_layer2\",stack_flag=False)\n",
    "        \n",
    "        output_seq = []\n",
    "        for t in range(max_len):\n",
    "            output_seq.append(word_clf(D_layer2[t],_embd_T))\n",
    "        _logits = tf.stack(output_seq,axis=1)\n",
    "        _prob = tf.nn.softmax(_logits,axis=-1)\n",
    "        \n",
    "    with tf.name_scope(\"Loss\"):\n",
    "        cross_entropy_0 = tf.map_fn(mask_catece,elems=(_prob,gt),dtype=tf.float32)\n",
    "        cross_entropy = tf.reduce_sum(cross_entropy_0*gt_mask,axis=-1)/tf.reduce_sum(gt_mask,axis=-1)\n",
    "        _loss = -tf.reduce_mean(cross_entropy)\n",
    "        \n",
    "    with tf.name_scope(\"Train_strategy\"):\n",
    "        opt = tf.train.AdamOptimizer(1e-4)\n",
    "        _update = opt.minimize(_loss)\n",
    "    \n",
    "    with tf.name_scope(\"Inference\"):\n",
    "        ## start at Encoder layer 2 : E_layer2\n",
    "        infer_out = tf.nn.embedding_lookup(_embd,infer_start)\n",
    "        infer_state_1 = e_state_1\n",
    "        infer_state_2 = e_state_2\n",
    "        \n",
    "        infer_pred_idx_seq = []\n",
    "        infer_logits_seq = []\n",
    "        for t in range(max_len):\n",
    "            infer_concat_vec = tf.concat([infer_out,var_vector[:,t]] , axis=-1)\n",
    "            if t==0:\n",
    "                tmp = Encoder([infer_concat_vec],128,name=\"D_layer0\",t_len=1,reuse=True,stack_flag=False)\n",
    "            else:\n",
    "                tmp = Encoder([infer_concat_vec],128,init_state=infer_state_0,name=\"D_layer0\",t_len=1,\n",
    "                              reuse=True,stack_flag=False)\n",
    "            infer_layer0 = tmp[0]\n",
    "            infer_state_0 = tmp[1]\n",
    "            \n",
    "            tmp = Encoder(infer_layer0,256,init_state=infer_state_1,\n",
    "                          t_len=1,name=\"E_layer_1\",reuse=True,stack_flag=False)\n",
    "            infer_layer1 = tmp[0]\n",
    "            infer_state_2 = tmp[1]\n",
    "            \n",
    "            tmp = attn_Decoder(infer_layer1,tf.stack(E_layer2,axis=1),in_mask,256,init_state=infer_state_2,\n",
    "                               t_len=1,name=\"ATTN_D_layer2\",reuse=True,stack_flag=False)\n",
    "            infer_layer2 , infer_state_2 , infer_score_seq = tmp\n",
    "            \n",
    "            infer_out = word_clf(infer_layer2[0],_embd_T)\n",
    "            infer_logits_seq.append(infer_out)\n",
    "            \n",
    "            out_index = tf.argmax(infer_out,axis=1)\n",
    "            infer_pred_idx_seq.append(out_index)\n",
    "            infer_out = tf.nn.embedding_lookup(_embd , out_index)\n",
    "            \n",
    "        infer_pred_idx_seq = tf.stack(infer_pred_idx_seq,axis=1)\n",
    "        infer_logits = tf.stack(infer_logits_seq,axis=1)\n",
    "        infer_prob = tf.nn.softmax(infer_logits,axis=-1)\n",
    "        \n",
    "    _init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver(max_to_keep=10)\n",
    "    \n",
    "print(\"Finish Building!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(graph=Seq_g,config=sess_opt)\n",
    "sess.run(_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(i):\n",
    "    my_dict = {\n",
    "        _in:idx_in_sen[i],\n",
    "        _in_mask:mask_in[i],\n",
    "        _out:idx_out_sen[i],\n",
    "        _out_mask:mask_out[i],\n",
    "        _out_gra:idx_gramma[i],\n",
    "        _out_len:length[i],\n",
    "        _out_rhy:idx_rhy[i]\n",
    "    }\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step     7 loss :   10.8872 time :   24.31\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-b40db7ab7bd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"step {:>5d} loss : {:>9.4f} time : {:>7.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/DSML/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/DSML/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/DSML/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/DSML/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/DSML/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/DSML/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 450\n",
    "n_epoch = 60\n",
    "n_step = idx_in_sen.shape[0]//batch_size\n",
    "\n",
    "r_index = np.arange(idx_in_sen.shape[0])\n",
    "loss_list = []\n",
    "\n",
    "for e in range(1,n_epoch+1):\n",
    "    np.random.shuffle(r_index)\n",
    "    start_time = time.time()\n",
    "    start = 0\n",
    "    for s in range(n_step):\n",
    "        idx = r_index[start:start+batch_size]\n",
    "        _,l = sess.run([_update,_loss] , feed_dict=get_batch(idx))\n",
    "        start += batch_size\n",
    "        print(\"step {:>5d} loss : {:>9.4f} time : {:>7.2f}\".format(s,l,time.time()-start_time) , end=\"\\r\")\n",
    "    \n",
    "    loss_list.append(l)\n",
    "    print(\"Epoch {0:>3d}/{1:d} loss : {2:>9.4f} time : {3:>8.2f}\".format(e,n_epoch,l,time.time()-start_time))\n",
    "    if e%3 == 0:\n",
    "        saver.save(sess,os.path.join(model_path,\"model_{}.ckpt\".format(e)))\n",
    "        pickle.dump(loss_list,open(os.path.join(log_path,\"loss.pkl\") , \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSML",
   "language": "python",
   "name": "dsml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
